# Project_ETL

## Team
- Daniel Jones and Will Copeland

## Project Proposal

## Finding Data
  - Project must use 2 or more sources of data

## Data Cleanup & Analysis
  - Once you have identified your datasets, perform ETL on the data. Make sure to plan and document the following:
      - The sources of data that you will extract from
      - The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc)
      - The type of final production database to load the data into (relational or non-relational)
      - The final tables or collections that will be used in the production database


# Project Report
  - Submit a final technical report with the above information and steps required to reproduce your ETL process

## Step 1: Identify data sources
  1. [Frontiers in Neuroscience Journal Articles](https://www.kaggle.com/markoarezina/frontiers-in-neuroscience-articles)
      - Articles and metadata from the Frontiers in Neuroscience journal series
      - This data set can be downloaded as a csv file from Kaggle
      - The file from Kaggle is 238 MB, as such, this file was saved in the folder "data_large", which was marked in .gitignore
  2. [World Health Organization: Mental health governance Data by country](http://apps.who.int/gho/data/node.main.MHPOLFIN?lang=en)

## Step 2: Extract: 
  - Original data sources and how the data was formatted (CSV, JSON, pgAdmin 4, etc)
  - Sources of data that were extract from


## Step 3: Transform:
  - What data cleaning or transformation was required
  - Type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc)
  

## Step 4: Create database | Load:
  - The type of final production database to load the data into (relational or non-relational)
  - The final tables or collections that will be used in the production database
  - Final database, tables/collections, and why this was chosen
